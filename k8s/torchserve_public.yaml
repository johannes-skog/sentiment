---
kind: Service
apiVersion: v1
metadata:
  name: torchserve
  labels:
    app: torchserve
spec:
  ports:
  - name: preds
    port: 8080
    targetPort: ts 
  - name: mdl
    port: 8081
    targetPort: ts-management
  - name: metrics
    port: 8082
    targetPort: ts-metrics
  type: LoadBalancer
  selector:
    app: torchserve
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: torchserve
  labels:
    app: torchserve
spec:
  replicas: 1
  selector:
    matchLabels:
      app: torchserve
  template:
    metadata:
      labels:
        app: torchserve
    spec:
      volumes:
      - name: model-store
        persistentVolumeClaim:
          claimName: model-store-claim
      containers:
      - name: torchserve
        image: pytorch/torchserve:latest-gpu
        # command: [ "sleep" ]
        # args: [ "infinity" ]
        args: ["torchserve", "--start",  "--model-store", "/mnt/azure/model-store/", "--ts-config", "/mnt/azure/config/config.properties"]
        ports:
        - name: ts
          containerPort: 8080
        - name: ts-management
          containerPort: 8081
        - name: ts-metrics
          containerPort: 8082
        imagePullPolicy: IfNotPresent
        volumeMounts:
          - mountPath: "/mnt/azure"
            name: model-store
        resources:
          requests:
            cpu: 500m
            memory: 128Mi
          limits:
            cpu: 2
            memory: 4Gi